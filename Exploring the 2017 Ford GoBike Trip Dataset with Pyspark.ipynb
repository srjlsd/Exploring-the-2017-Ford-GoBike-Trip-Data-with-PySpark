{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590541f1",
   "metadata": {},
   "source": [
    "# <center> Exploring the 2017 Ford GoBike Trip Data with PySpark \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3234a96",
   "metadata": {},
   "source": [
    "# $\\color{red}{\\text{Content Outline:}}$\n",
    "\n",
    " ## 1-calculate distance of each trip using haversine library and add the result to the dataset\n",
    " ## 2-calculate the duration in seconds of each trip\n",
    " ## 3-by assuming each minute cost 0.35 cent calculate the fee for each trip\n",
    " ## 4-calculate the total distance for each bike and list the top 10\n",
    " ## 5-calculate the number of trips for each start station list top 10 and find the ratio of using as male or female\n",
    " ## 6-make a comparison to find the percentage of usage for customer and subscriber\n",
    " ## 7-calculate the age of all users and show the relation between the distance and the age\n",
    " ## 8-calculate the total cost for all customers and all subscribers\n",
    " ## 9- what is the ratio of payment using cc or app wallet\n",
    " ## 10-what is the preferred way to pay for customers and subscriber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabaf8e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d13d9a20",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0fff2",
   "metadata": {},
   "source": [
    " ## 1-calculate distance of each trip using haversine library and add the result to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f52f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sqrt\n",
    "\n",
    "# Download the CSV file from the remote URL\n",
    "url = \"https://raw.githubusercontent.com/srjlsd/Exploring-the-2017-Ford-GoBike-Trip-Data-with-PySpark/15ccf0249d3da47c41400ca1cd6c092c308b6287/2017-fordgobike-trip-data.csv\"\n",
    "local_path = \"2017-fordgobike-trip-data.csv\"\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "# Initialize the SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "\n",
    "# Read the CSV file using PySpark\n",
    "df = spark.read.csv(local_path, header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3af5bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+------------------+\n",
      "|start_time|end_time|start_station_id|  start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude|bike_id| user_type|member_birth_year|member_gender|     pyment|        distance_m|\n",
      "+----------+--------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+------------------+\n",
      "|   57:39.7| 12:50.2|              74|Laguna St at Haye...|           37.77643482|            -122.426244|            43|San Francisco Pub...|          37.7787677|         -122.4159292|     96|  Customer|             1987|         Male|credit card| 942.3373818591812|\n",
      "|   56:34.8| 49:55.6|             284|Yerba Buena Cente...|           37.78487208|           -122.4008757|            96|Dolores St at 15t...|          37.7662102|         -122.4266136|     88|  Customer|             1965|       Female|credit card|3067.7986569378118|\n",
      "|   45:48.4| 28:36.9|             245|Downtown Berkeley...|            37.8703477|           -122.2677637|           245|Downtown Berkeley...|          37.8703477|         -122.2677637|   1094|  Customer|             null|         null|credit card|               0.0|\n",
      "|   31:10.6| 47:23.5|              60|8th St at Ringold St|            37.7745204|           -122.4094494|             5|Powell St BART St...|         37.78389936|         -122.4084449|   2831|  Customer|             null|         null|credit card|1045.9655184811572|\n",
      "|   23:14.0| 29:57.6|             239|Bancroft Way at T...|            37.8688126|            -122.258764|           247|Fulton St at Banc...|          37.8677892|         -122.2658964|   3167|Subscriber|             1997|       Female| app wallet|  635.939861076868|\n",
      "|   51:00.9| 24:47.2|              30|San Francisco Cal...|             37.776598|            -122.395282|            30|San Francisco Cal...|           37.776598|          -122.395282|   1487|  Customer|             null|         null| app wallet|               0.0|\n",
      "|   49:28.4| 04:35.6|             259|Addison St at Fou...|             37.866249|           -122.2993708|           259|Addison St at Fou...|           37.866249|         -122.2993708|   3539|  Customer|             1991|       Female| app wallet|               0.0|\n",
      "|   46:37.2| 58:51.2|             284|Yerba Buena Cente...|           37.78487208|           -122.4008757|           284|Yerba Buena Cente...|         37.78487208|         -122.4008757|   1503|  Customer|             null|         null| app wallet|               0.0|\n",
      "|   37:07.5| 46:18.3|              20|Mechanics Monumen...|               37.7913|            -122.399051|            20|Mechanics Monumen...|             37.7913|          -122.399051|   3125|  Customer|             null|         null| app wallet|               0.0|\n",
      "|   35:38.1| 46:17.1|              20|Mechanics Monumen...|               37.7913|            -122.399051|            20|Mechanics Monumen...|             37.7913|          -122.399051|   2543|  Customer|             null|         null| app wallet|               0.0|\n",
      "+----------+--------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.functions import acos, cos, sin, radians, least\n",
    "#from pyspark.sql.functions import acos, cos, sin, sqrt, lit\n",
    "from pyspark.sql.functions import sin, cos, sqrt, asin, radians, least, acos, col, lit\n",
    "\n",
    "\n",
    "def haversine(lat1, long1, lat2, long2):\n",
    "    lat1, long1, lat2, long2 = radians(lat1), radians(long1), radians(lat2), radians(long2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = long2 - long1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    m = 6367 * c * 1000\n",
    "    return m\n",
    "\n",
    "\n",
    "# Read the dataset into a Spark DataFrame\n",
    "df = spark.read.csv(r'E:\\Learning Pandas\\Data_Manupilation\\2017-fordgobike-tripdata.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Calculate the distance for each trip using the Haversine function\n",
    "df = df.withColumn('distance_m', haversine('start_station_latitude', 'start_station_longitude', 'end_station_latitude', 'end_station_longitude'))\n",
    "\n",
    "# Show the first 10 rows of the updated DataFrame\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ee5bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        distance_m|\n",
      "+------------------+\n",
      "| 942.3373818591812|\n",
      "|3067.7986569378118|\n",
      "|               0.0|\n",
      "|1045.9655184811572|\n",
      "|  635.939861076868|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('distance_m').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e12528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median distance: 1398.85 meters\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import percentile_approx\n",
    "\n",
    "# Get the median trip distance\n",
    "median_distance = df.selectExpr(\"percentile_approx(distance_m, 0.5)\").collect()[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(\"Median distance: {:.2f} meters\".format(median_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8577c",
   "metadata": {},
   "source": [
    " ## 2-calculate the duration in seconds of each trip\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "069d8f98",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import abs\n",
    "\n",
    "df = df.withColumn('start_time', expr(\"to_timestamp(start_time, 'mm:ss.S')\"))\n",
    "df = df.withColumn('end_time', expr(\"to_timestamp(end_time, 'mm:ss.S')\"))\n",
    "\n",
    "df = df.withColumn('duration_sec', abs(df.end_time.cast('long') - df.start_time.cast('long')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689806af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, when, col\n",
    "\n",
    "df = df.withColumn('start_time', expr(\"to_timestamp(start_time, 'mm:ss.S')\"))\n",
    "df = df.withColumn('end_time', expr(\"to_timestamp(end_time, 'mm:ss.S')\"))\n",
    "\n",
    "df = df.withColumn('duration_sec',\n",
    "                   when(col('end_time') < col('start_time'),\n",
    "                        (col('end_time').cast('long') + 3600 - col('start_time').cast('long')))\n",
    "                   .otherwise(col('end_time').cast('long') - col('start_time').cast('long')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ad3f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- end_time: timestamp (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: double (nullable = true)\n",
      " |-- start_station_longitude: double (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: double (nullable = true)\n",
      " |-- end_station_longitude: double (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: integer (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      " |-- distance_m: double (nullable = true)\n",
      " |-- duration_sec: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() # _c0 is unneccery column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d32040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|duration_sec|\n",
      "+------------+\n",
      "|         911|\n",
      "|        3201|\n",
      "|        2568|\n",
      "|         973|\n",
      "|         403|\n",
      "|        2027|\n",
      "|         907|\n",
      "|         734|\n",
      "|         551|\n",
      "|         639|\n",
      "+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('duration_sec').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81fb4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average trip duration is 738.29 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Calculate the average trip duration in seconds\n",
    "avg_duration = df.agg(avg(\"duration_sec\")).collect()[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(\"The average trip duration is {:.2f} seconds\".format(avg_duration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1589a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary       duration_sec\n",
      "0   count             519700\n",
      "1    mean  738.2905522416779\n",
      "2  stddev  542.5280638280457\n",
      "3     min                  0\n",
      "4     max               3600\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Get summary statistics for trip duration column\n",
    "trip_duration_stats = df.select(\"duration_sec\").describe().toPandas()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(trip_duration_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9256f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary       duration_sec\n",
      "0   count             519700\n",
      "1    mean  738.2905522416779\n",
      "2  stddev  542.5280638280457\n",
      "3     min                  0\n",
      "4     max               3600\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Get summary statistics for trip duration column\n",
    "trip_duration_stats = df.select(\"duration_sec\").describe().toPandas()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(trip_duration_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb88692",
   "metadata": {},
   "source": [
    "## 3-by assuming each minute cost 0.35 cent calculate the fee for each trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8d8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "df = df.withColumn('fee', round(df.duration_sec/60 * 0.35, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e3a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|  fee|\n",
      "+-----+\n",
      "| 5.31|\n",
      "|18.67|\n",
      "|14.98|\n",
      "| 5.68|\n",
      "| 2.35|\n",
      "|11.82|\n",
      "| 5.29|\n",
      "| 4.28|\n",
      "| 3.21|\n",
      "| 3.73|\n",
      "+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('fee').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581570c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average fee is: 4.306755609005224\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Calculate the average fee\n",
    "avg_fee = df.agg(avg(\"fee\")).collect()[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(\"The average fee is:\", avg_fee)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c61de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary                 fee\n",
      "0   count              519700\n",
      "1    mean   4.306755609005224\n",
      "2  stddev  3.1647523390669736\n",
      "3     min                 0.0\n",
      "4     max                21.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Get summary statistics for trip fee column\n",
    "fee_description = df.select(\"fee\").describe().toPandas()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(fee_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0fce5",
   "metadata": {},
   "source": [
    "## 4-calculate the total distance for each bike and list the top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3dbfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|bike_id|total_distance|\n",
      "+-------+--------------+\n",
      "|     68|     742901.74|\n",
      "|   2178|     720728.46|\n",
      "|    256|     671493.31|\n",
      "|    235|     669740.32|\n",
      "|   2049|     656414.81|\n",
      "|    441|      656229.1|\n",
      "|   2226|      647415.6|\n",
      "|    796|      646460.7|\n",
      "|    190|     639891.29|\n",
      "|   2365|     639010.34|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group the data by bike_id and calculate the total distance for each bike\n",
    "grouped_data = df.groupBy(\"bike_id\").agg({\"distance_m\": \"sum\"})\n",
    "\n",
    "# Rename the column from sum(Distance_in_meter) to total_distance\n",
    "grouped_data = grouped_data.withColumnRenamed(\"sum(distance_m)\", \"total_distance\")\n",
    "\n",
    "# Round the total_distance column to 2 decimal places\n",
    "grouped_data = grouped_data.withColumn(\"total_distance\", round(\"total_distance\", 2))\n",
    "\n",
    "# Sort the data by total_distance in descending order and select the top 10\n",
    "top_10 = grouped_data.sort(grouped_data.total_distance.desc()).limit(10)\n",
    "\n",
    "# Show the results\n",
    "top_10.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06929a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5da74 th {\n",
       "  border: 1px solid black;\n",
       "  padding: 6px;\n",
       "}\n",
       "#T_5da74_row0_col0, #T_5da74_row0_col1, #T_5da74_row1_col0, #T_5da74_row1_col1, #T_5da74_row2_col0, #T_5da74_row2_col1, #T_5da74_row3_col0, #T_5da74_row3_col1, #T_5da74_row4_col0, #T_5da74_row4_col1, #T_5da74_row5_col0, #T_5da74_row5_col1, #T_5da74_row6_col0, #T_5da74_row6_col1, #T_5da74_row7_col0, #T_5da74_row7_col1, #T_5da74_row8_col0, #T_5da74_row8_col1, #T_5da74_row9_col0, #T_5da74_row9_col1 {\n",
       "  background-color: grey;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5da74\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5da74_level0_col0\" class=\"col_heading level0 col0\" >bike_id</th>\n",
       "      <th id=\"T_5da74_level0_col1\" class=\"col_heading level0 col1\" >total_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5da74_row0_col0\" class=\"data row0 col0\" >68</td>\n",
       "      <td id=\"T_5da74_row0_col1\" class=\"data row0 col1\" >742901.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5da74_row1_col0\" class=\"data row1 col0\" >2178</td>\n",
       "      <td id=\"T_5da74_row1_col1\" class=\"data row1 col1\" >720728.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5da74_row2_col0\" class=\"data row2 col0\" >256</td>\n",
       "      <td id=\"T_5da74_row2_col1\" class=\"data row2 col1\" >671493.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5da74_row3_col0\" class=\"data row3 col0\" >235</td>\n",
       "      <td id=\"T_5da74_row3_col1\" class=\"data row3 col1\" >669740.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5da74_row4_col0\" class=\"data row4 col0\" >2049</td>\n",
       "      <td id=\"T_5da74_row4_col1\" class=\"data row4 col1\" >656414.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5da74_row5_col0\" class=\"data row5 col0\" >441</td>\n",
       "      <td id=\"T_5da74_row5_col1\" class=\"data row5 col1\" >656229.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5da74_row6_col0\" class=\"data row6 col0\" >2226</td>\n",
       "      <td id=\"T_5da74_row6_col1\" class=\"data row6 col1\" >647415.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5da74_row7_col0\" class=\"data row7 col0\" >796</td>\n",
       "      <td id=\"T_5da74_row7_col1\" class=\"data row7 col1\" >646460.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5da74_row8_col0\" class=\"data row8 col0\" >190</td>\n",
       "      <td id=\"T_5da74_row8_col1\" class=\"data row8 col1\" >639891.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5da74_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5da74_row9_col0\" class=\"data row9 col0\" >2365</td>\n",
       "      <td id=\"T_5da74_row9_col1\" class=\"data row9 col1\" >639010.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fb8ca1b910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the PySpark dataframe to a pandas dataframe\n",
    "pandas_df = top_10.toPandas()\n",
    "\n",
    "# Define custom style function\n",
    "def style_table(df):\n",
    "    return df.style.set_properties(**{'background-color': 'grey',\n",
    "                                      'color': 'black',\n",
    "                                      'font-weight': 'bold',\n",
    "                                      'text-align': 'center'})\\\n",
    "                    .set_table_styles([{'selector': 'th',\n",
    "                                        'props': [('border', '1px solid black'),\n",
    "                                                  ('padding', '6px')]}])\n",
    "\n",
    "# Apply custom styles\n",
    "styled_table = style_table(pandas_df)\n",
    "\n",
    "# Display the table\n",
    "display(styled_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20935346",
   "metadata": {},
   "source": [
    "## 5-calculate the number of trips for each start station list top 10 and find the ratio of using as male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bcdd609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+---------------+\n",
      "|start_station_name                                       |number_of_trips|\n",
      "+---------------------------------------------------------+---------------+\n",
      "|San Francisco Ferry Building (Harry Bridges Plaza)       |15187          |\n",
      "|The Embarcadero at Sansome St                            |13664          |\n",
      "|San Francisco Caltrain (Townsend St at 4th St)           |12546          |\n",
      "|San Francisco Caltrain Station 2  (Townsend St at 4th St)|12055          |\n",
      "|Market St at 10th St                                     |11960          |\n",
      "|Montgomery St BART Station (Market St at 2nd St)         |11334          |\n",
      "|Berry St at 4th St                                       |10956          |\n",
      "|Powell St BART Station (Market St at 4th St)             |10142          |\n",
      "|Howard St at Beale St                                    |9926           |\n",
      "|Steuart St at Market St                                  |9347           |\n",
      "+---------------------------------------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Increase the column width\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.maxNumRows\", \"500\")\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.maxNumCols\", \"500\")\n",
    "\n",
    "# Group the data by start station and count the number of trips\n",
    "grouped_data = df.groupBy(\"start_station_name\").agg(count(\"start_station_name\").alias(\"number_of_trips\"))\n",
    "\n",
    "# Sort the data by number_of_trips in descending order and select the top 10\n",
    "top_10 = grouped_data.sort(grouped_data.number_of_trips.desc()).limit(10)\n",
    "\n",
    "# Show the results\n",
    "top_10.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7acfab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b853b th {\n",
       "  border: 1px solid black;\n",
       "  padding: 6px;\n",
       "}\n",
       "#T_b853b_row0_col0, #T_b853b_row0_col1, #T_b853b_row1_col0, #T_b853b_row1_col1, #T_b853b_row2_col0, #T_b853b_row2_col1, #T_b853b_row3_col0, #T_b853b_row3_col1, #T_b853b_row4_col0, #T_b853b_row4_col1, #T_b853b_row5_col0, #T_b853b_row5_col1, #T_b853b_row6_col0, #T_b853b_row6_col1, #T_b853b_row7_col0, #T_b853b_row7_col1, #T_b853b_row8_col0, #T_b853b_row8_col1, #T_b853b_row9_col0, #T_b853b_row9_col1 {\n",
       "  background-color: grey;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b853b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b853b_level0_col0\" class=\"col_heading level0 col0\" >start_station_name</th>\n",
       "      <th id=\"T_b853b_level0_col1\" class=\"col_heading level0 col1\" >number_of_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b853b_row0_col0\" class=\"data row0 col0\" >San Francisco Ferry Building (Harry Bridges Plaza)</td>\n",
       "      <td id=\"T_b853b_row0_col1\" class=\"data row0 col1\" >15187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b853b_row1_col0\" class=\"data row1 col0\" >The Embarcadero at Sansome St</td>\n",
       "      <td id=\"T_b853b_row1_col1\" class=\"data row1 col1\" >13664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b853b_row2_col0\" class=\"data row2 col0\" >San Francisco Caltrain (Townsend St at 4th St)</td>\n",
       "      <td id=\"T_b853b_row2_col1\" class=\"data row2 col1\" >12546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b853b_row3_col0\" class=\"data row3 col0\" >San Francisco Caltrain Station 2  (Townsend St at 4th St)</td>\n",
       "      <td id=\"T_b853b_row3_col1\" class=\"data row3 col1\" >12055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b853b_row4_col0\" class=\"data row4 col0\" >Market St at 10th St</td>\n",
       "      <td id=\"T_b853b_row4_col1\" class=\"data row4 col1\" >11960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b853b_row5_col0\" class=\"data row5 col0\" >Montgomery St BART Station (Market St at 2nd St)</td>\n",
       "      <td id=\"T_b853b_row5_col1\" class=\"data row5 col1\" >11334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b853b_row6_col0\" class=\"data row6 col0\" >Berry St at 4th St</td>\n",
       "      <td id=\"T_b853b_row6_col1\" class=\"data row6 col1\" >10956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b853b_row7_col0\" class=\"data row7 col0\" >Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td id=\"T_b853b_row7_col1\" class=\"data row7 col1\" >10142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b853b_row8_col0\" class=\"data row8 col0\" >Howard St at Beale St</td>\n",
       "      <td id=\"T_b853b_row8_col1\" class=\"data row8 col1\" >9926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b853b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b853b_row9_col0\" class=\"data row9 col0\" >Steuart St at Market St</td>\n",
       "      <td id=\"T_b853b_row9_col1\" class=\"data row9 col1\" >9347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fb876a8040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the PySpark dataframe to a pandas dataframe\n",
    "pandas_df = top_10.toPandas()\n",
    "\n",
    "# Define custom style function\n",
    "def style_table(df):\n",
    "    return df.style.set_properties(**{'background-color': 'grey',\n",
    "                                      'color': 'black',\n",
    "                                      'font-weight': 'bold',\n",
    "                                      'text-align': 'center'})\\\n",
    "                    .set_table_styles([{'selector': 'th',\n",
    "                                        'props': [('border', '1px solid black'),\n",
    "                                                  ('padding', '6px')]}])\n",
    "\n",
    "# Apply custom styles\n",
    "styled_table = style_table(pandas_df)\n",
    "\n",
    "# Display the table\n",
    "display(styled_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c19cdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----+\n",
      "|member_gender|gender_count|ratio|\n",
      "+-------------+------------+-----+\n",
      "|         null|           0|  0.0|\n",
      "|       Female|       98621| 0.22|\n",
      "|        Other|        6299| 0.01|\n",
      "|         Male|      348318| 0.77|\n",
      "+-------------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum, col, round\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Group the data by member_gender and calculate the count for each gender\n",
    "gender_count = df.groupBy(\"member_gender\").agg(count(\"member_gender\").alias(\"gender_count\"))\n",
    "\n",
    "# Calculate the total count of all genders\n",
    "total_count = gender_count.agg(sum(\"gender_count\")).collect()[0][0]\n",
    "\n",
    "# Calculate the ratio of each gender and round to 2 decimal places\n",
    "gender_ratio = gender_count.withColumn(\"ratio\", round(col(\"gender_count\") / total_count, 2))\n",
    "\n",
    "# Show the results\n",
    "gender_ratio.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c02526e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b00f6 th {\n",
       "  border: 1px solid black;\n",
       "  padding: 6px;\n",
       "}\n",
       "#T_b00f6_row0_col0, #T_b00f6_row0_col1, #T_b00f6_row0_col2, #T_b00f6_row1_col0, #T_b00f6_row1_col1, #T_b00f6_row1_col2, #T_b00f6_row2_col0, #T_b00f6_row2_col1, #T_b00f6_row2_col2, #T_b00f6_row3_col0, #T_b00f6_row3_col1, #T_b00f6_row3_col2 {\n",
       "  background-color: grey;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b00f6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b00f6_level0_col0\" class=\"col_heading level0 col0\" >member_gender</th>\n",
       "      <th id=\"T_b00f6_level0_col1\" class=\"col_heading level0 col1\" >gender_count</th>\n",
       "      <th id=\"T_b00f6_level0_col2\" class=\"col_heading level0 col2\" >ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b00f6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b00f6_row0_col0\" class=\"data row0 col0\" >None</td>\n",
       "      <td id=\"T_b00f6_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_b00f6_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b00f6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b00f6_row1_col0\" class=\"data row1 col0\" >Female</td>\n",
       "      <td id=\"T_b00f6_row1_col1\" class=\"data row1 col1\" >98621</td>\n",
       "      <td id=\"T_b00f6_row1_col2\" class=\"data row1 col2\" >0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b00f6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b00f6_row2_col0\" class=\"data row2 col0\" >Other</td>\n",
       "      <td id=\"T_b00f6_row2_col1\" class=\"data row2 col1\" >6299</td>\n",
       "      <td id=\"T_b00f6_row2_col2\" class=\"data row2 col2\" >0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b00f6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b00f6_row3_col0\" class=\"data row3 col0\" >Male</td>\n",
       "      <td id=\"T_b00f6_row3_col1\" class=\"data row3 col1\" >348318</td>\n",
       "      <td id=\"T_b00f6_row3_col2\" class=\"data row3 col2\" >0.770000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fb8ca2d8e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_df = gender_ratio.toPandas()\n",
    "# Apply custom styles\n",
    "styled_table = style_table(pandas_df)\n",
    "# Display the table\n",
    "display(styled_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357bbda2",
   "metadata": {},
   "source": [
    " ## 6-make a comparison to find the percentage of usage for customer and subscriber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcce3120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+\n",
      "| user_type| total|percantage|\n",
      "+----------+------+----------+\n",
      "|Subscriber|409230|      79.0|\n",
      "|  Customer|110470|      21.0|\n",
      "+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_user = df.groupBy('user_type').agg(count('*').alias('total'))\n",
    "\n",
    "percent_user.withColumn('percantage',round(col('total')/ df.count()*100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "465f2419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_250fa th {\n",
       "  border: 1px solid black;\n",
       "  padding: 6px;\n",
       "}\n",
       "#T_250fa_row0_col0, #T_250fa_row0_col1, #T_250fa_row1_col0, #T_250fa_row1_col1 {\n",
       "  background-color: grey;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_250fa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_250fa_level0_col0\" class=\"col_heading level0 col0\" >user_type</th>\n",
       "      <th id=\"T_250fa_level0_col1\" class=\"col_heading level0 col1\" >total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_250fa_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_250fa_row0_col0\" class=\"data row0 col0\" >Subscriber</td>\n",
       "      <td id=\"T_250fa_row0_col1\" class=\"data row0 col1\" >409230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_250fa_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_250fa_row1_col0\" class=\"data row1 col0\" >Customer</td>\n",
       "      <td id=\"T_250fa_row1_col1\" class=\"data row1 col1\" >110470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fb85d13580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_df = gender_ratio.toPandas()\n",
    "# Apply custom styles\n",
    "styled_table = style_table(pandas_df)\n",
    "# Display the table\n",
    "display(styled_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7c6cf",
   "metadata": {},
   "source": [
    " ## 7-calculate the age of all users and show the relation between the distance and the age"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e04a4c6",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import datediff, year, round, dayofyear, date_sub, to_date\n",
    "\n",
    "# Convert the member_birth_year column to a date data type\n",
    "df = df.withColumn(\"member_birth_year\", to_date(df[\"member_birth_year\"].cast(\"string\"), \"yyyy\"))\n",
    "\n",
    "# Calculate the age of each user based on their birth year\n",
    "df = df.withColumn(\"age\", round(datediff(df[\"start_time\"], date_sub(df[\"member_birth_year\"], 365*dayofyear(df[\"member_birth_year\"]))) / 365))\n",
    "\n",
    "# Show the relation between the distance and the age\n",
    "df.groupBy(\"age\").agg({\"distance_m\": \"mean\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f951e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ed5b8c5f",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import datediff, year, round, dayofyear, date_sub\n",
    "\n",
    "# Calculate the age of each user based on their birth year\n",
    "df = df.withColumn(\"age\", round(datediff(df[\"start_time\"], date_sub(df[\"member_birth_year\"], 365*dayofyear(df[\"member_birth_year\"]))) / 365))\n",
    "\n",
    "# Filter out rows with negative age values\n",
    "df = df.filter(df.age >= 5)\n",
    "\n",
    "# Show the relation between the distance and the age\n",
    "df.groupBy(\"age\").agg({\"distance_m\": \"mean\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0683e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the age of each user\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df1 = df.withColumn(\"age\", 2017 - F.col(\"member_birth_year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df1.select(col('age'),('distance_m')).show(10)\n",
    "df_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90747cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the correlation between age and total distance\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df1.stat.corr(\"age\",\"distance_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show the relation between the distance and the age\n",
    "df1.groupBy(\"age\").agg({\"distance_m\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f91910",
   "metadata": {},
   "source": [
    " ## 8-calculate the total cost for all customers and all subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b9a7ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "| user_type|total_paid_sum|\n",
      "+----------+--------------+\n",
      "|Subscriber|      201784.0|\n",
      "|  Customer|       58410.0|\n",
      "+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('total_paid', \n",
    "                   round((df.distance_m/ 1000) * .35)) # assume 35 cent for every meter\n",
    "\n",
    "\n",
    "df.groupBy(\"user_type\").agg(sum('total_paid')\n",
    "                            .alias('total_paid_sum')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51281a84",
   "metadata": {},
   "source": [
    " ## 9- what is the ratio of payment using cc or app wallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f32e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|     pyment|number of usage|\n",
      "+-----------+---------------+\n",
      "| app wallet|         260061|\n",
      "|credit card|         259639|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the ratio of payment using cc or app wallet\n",
    "\n",
    "df.groupBy('pyment').agg(count('*').alias('number of usage')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cdd11",
   "metadata": {},
   "source": [
    " ## 10-what is the preferred way to pay for customers and subscriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1acba5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------------+\n",
      "|     pyment|total_on_type|               perc|\n",
      "+-----------+-------------+-------------------+\n",
      "| app wallet|       260061| 0.5004060034635367|\n",
      "|credit card|       259639|0.49959399653646336|\n",
      "+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('pyment').agg(count('*').alias('total_on_type'))\\\n",
    ".withColumn('perc', col('total_on_type') / df.count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d0ed4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupBy('user_type', 'pyment').agg(count('*').alias('row_count')).withColumnRenamed('pyment', 'payment').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946d762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c90a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd3d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6917306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d9aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
